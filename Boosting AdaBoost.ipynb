{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Boosting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_weights(n):\n",
    "    return np.full(n,1/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\epsilon_t = \\sum_{i=1}^nw_t(i)\\mathbb{1}\\{y_i\\ne f_t(x_i)\\}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_epsilon(y_true, y_pred, weights):\n",
    "    summ=0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]!=y_pred[i]:\n",
    "            summ=summ+weights[i]\n",
    "    return np.float(summ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\alpha_t = \\frac12ln(\\frac{1-\\epsilon_t}{\\epsilon_t})$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha(epsilon):\n",
    "    if epsilon==0:\n",
    "        return np.inf\n",
    "    else:\n",
    "        return 0.5*np.log((1-epsilon)/epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[5, 5],\n",
      "       [5, 5],\n",
      "       [1, 1],\n",
      "       [2, 2],\n",
      "       [4, 4]]), array([1, 1, 1, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "def boot_strap_selection(X, y, weights):\n",
    "    bss_indicies = np.random.choice(range(len(y)), size = len(y), p = weights)\n",
    "    \n",
    "    # Subset arrays with indicies\n",
    "    return X[bss_indicies,:], y[bss_indicies]\n",
    "\n",
    "### Example of use\n",
    "X = np.array([[1,1],[2,2],[3,3],[4,4],[5,5]])\n",
    "y = np.array([1,0,1,0,1])\n",
    "weights = np.array([.35,.1,.1,.35,.1])\n",
    "\n",
    "print(boot_strap_selection(X,y, weights))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_{t+1}(i) = \\frac{\\hat{w}_{t+1}(i)}{\\sum_j\\hat{w}_{t+1}(j)}$$  \n",
    "\n",
    "\n",
    "$$\\hat{w}_{t+1}(i) = w_t(i)e^{-\\alpha_ty_if_t(x_i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, alpha, y_true, y_pred):\n",
    "    def target_for_weight_update(y):\n",
    "        toRet=y.copy()\n",
    "        toRet[toRet==0]=-1\n",
    "        return toRet\n",
    "    y=target_for_weight_update(y_true)\n",
    "    pred=target_for_weight_update(y_pred)\n",
    "    weights=weights*np.exp(-alpha*y*pred)\n",
    "    weights=weights/sum(weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from boosted trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, est_dict):\n",
    "    fin_preds=np.zeros(X.shape[0])\n",
    "    for k in est_dict:\n",
    "        preds=est_dict[k][0].predict(X)\n",
    "        preds[preds<1]=-1\n",
    "        preds=preds*est_dict[k][1]\n",
    "        fin_preds +=preds\n",
    "    fin_preds[fin_preds>=0]=1\n",
    "    fin_preds[fin_preds<0]=0\n",
    "    return fin_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$f_{boost}(x_0) = sign(\\sum_{t=1}^T\\alpha_tf_t(X_0))$$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, est_dict):\n",
    "    fin_preds=np.zeros(X.shape[0])\n",
    "    for k in est_dict:\n",
    "        preds=est_dict[k][0].predict(X)\n",
    "        preds[preds<1]=-1\n",
    "        preds=preds*est_dict[k][1]\n",
    "        fin_preds +=preds\n",
    "    fin_preds[fin_preds>=0]=1\n",
    "    fin_preds[fin_preds<0]=0\n",
    "    return fin_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:\n",
      "      x    y  classification\n",
      "0  0.5  3.0               1\n",
      "1  1.0  2.0               1\n",
      "2  3.0  0.5              -1\n",
      "3  2.0  3.0              -1\n",
      "4  3.0  4.0               1\n",
      "5  3.5  2.5              -1\n",
      "6  3.6  4.7               1\n",
      "7  4.0  4.2               1\n",
      "8  4.5  2.0              -1\n",
      "9  4.7  4.5              -1 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=1,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#provided, shortened\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def simple_tree():\n",
    "    return DecisionTreeClassifier(criterion = 'entropy', max_depth= 1)\n",
    "\n",
    "#example\n",
    "pts = [[.5, 3,1],[1,2,1],[3,.5,-1],[2,3,-1],[3,4,1],\n",
    " [3.5,2.5,-1],[3.6,4.7,1],[4,4.2,1],[4.5,2,-1],[4.7,4.5,-1]]\n",
    "\n",
    "df = pd.DataFrame(pts, columns = ['x','y','classification'])\n",
    "\n",
    "# Plotting by category\n",
    "\n",
    "b = df[df.classification ==1]\n",
    "r = df[df.classification ==-1]\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.scatter(b.x, b.y, color = 'b', marker=\"+\", s = 400)\n",
    "plt.scatter(r.x, r.y, color = 'r', marker = \"o\", s = 400)\n",
    "plt.title(\"Categories Denoted by Color/Shape\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"df:\\n\",df, \"\\n\")\n",
    "\n",
    "### split out X and y\n",
    "X = df[['x','y']]\n",
    "\n",
    "# Change from -1 and 1 to 0 and 1\n",
    "y = np.array([1 if x == 1 else 0 for x in df['classification']])\n",
    "\n",
    "### Split data in half\n",
    "X1 = X.iloc[:len(X.index)//2, :]\n",
    "X2 = X.iloc[len(X.index)//2:, :]\n",
    "\n",
    "y1 = y[:len(y)//2]\n",
    "y2 = y[len(X)//2:]\n",
    "\n",
    "\n",
    "### Fit classifier to both sets of data, save to dictionary:\n",
    "\n",
    "tree_dict = {}\n",
    "\n",
    "tree1 = simple_tree()\n",
    "tree1.fit(X1,y1)\n",
    "\n",
    "\n",
    "### made up alpha, for example\n",
    "alpha1 = .6\n",
    "tree_dict[1] = (tree1, alpha1)\n",
    "\n",
    "tree2 = simple_tree()\n",
    "tree2.fit(X2,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_adaboost_fit(X,y, n_estimators):\n",
    "    def simple_tree():\n",
    "        return DecisionTreeClassifier(criterion = 'entropy', max_depth= 1)\n",
    "    \n",
    "    # Create default weights array where all are equal to 1/n\n",
    "    weights = default_weights(len(y)) ### <------\n",
    "    \n",
    "    est_dict = {}\n",
    "    for i in range(n_estimators):\n",
    "        # Create bootstrap sample\n",
    "        bs_X, bs_y = boot_strap_selection(X, y, weights)\n",
    "        \n",
    "#         print(bs_X,bs_y)\n",
    "#         break\n",
    "        mod = simple_tree()\n",
    "        mod.fit(bs_X, bs_y)\n",
    "        \n",
    "        # Note: Predicting on all values of X, NOT boot-strap\n",
    "        preds = mod.predict(X)\n",
    "        \n",
    "        epsilon = calc_epsilon(y, preds, weights) ### <------\n",
    "        alpha = calc_alpha(epsilon) ### <------\n",
    "        \n",
    "        # Note that the i+1-th model will be keyed to the int i,\n",
    "        # and will store a tuple of the fit model and the alpha value\n",
    "        est_dict[i] = (mod, alpha)\n",
    "        \n",
    "        weights = update_weights(weights, alpha, y, preds) ### <------\n",
    "    \n",
    "    return est_dict\n",
    "#     return bs_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\n",
    "\"age\", \"workclass\", \"fnlwgt\", \"education\",\n",
    "\"education-num\", \"marital-status\", \"occupation\", \"relationship\",\n",
    "\"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\",\n",
    "\"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "data_path = \"./week7dataset.data\"\n",
    "\n",
    "data = pd.read_csv(data_path, header = None, names = col_names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided, altered\n",
    "def preprocess_census(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    ### Hardcode variables which need categorical encoding\n",
    "    to_encode = [\"workclass\", \"occupation\", \"sex\"]\n",
    "\n",
    "    ### Find top categories in categorical columns\n",
    "    ### Used for dropping majority class to prevent multi-colinearity\n",
    "    top_categories = []\n",
    "\n",
    "    for col in to_encode:\n",
    "        top_categories.append(X_train[col].value_counts().index[0])\n",
    "\n",
    "    ### Create and fit one-hot encoder for categoricals\n",
    "    OHE = OneHotEncoder(sparse = False)\n",
    "    OHE.fit(X_train[to_encode])\n",
    "\n",
    "    ## Create and fit Label encoder for target\n",
    "    LabEnc = LabelEncoder()\n",
    "    LabEnc.fit(y_train)\n",
    "\n",
    "    def create_encoded_df(X, to_encode = to_encode, OHE = OHE, top_categories = top_categories):\n",
    "        # Return columns which need encoding.\n",
    "        def return_encoded_cols(X, to_encode = to_encode, OHE = OHE, top_categories = top_categories):\n",
    "            # Use onehotencoder to transform.\n",
    "            # Use \"categories\" to name\n",
    "            toRet = pd.DataFrame(OHE.transform(X[to_encode]), columns = np.concatenate(OHE.categories_))\n",
    "\n",
    "            # Drop top_categories and return\n",
    "            return toRet.drop(top_categories, axis = 1)\n",
    "\n",
    "        # create encoded columns\n",
    "        ret_cols = return_encoded_cols(X)\n",
    "\n",
    "        # Drop columns that were encoded\n",
    "        dr_enc = X.drop(to_encode, axis = 1)\n",
    "\n",
    "        # Concatenate values\n",
    "        # use index from original data\n",
    "        # use combined column names\n",
    "#         return pd.DataFrame(np.concatenate([ret_cols.values, dr_enc.values],axis = 1),\n",
    "#                             index = dr_enc.index,\n",
    "#                             columns = list(ret_cols.columns) + list(dr_enc.columns))\n",
    "\n",
    "        return ret_cols\n",
    "\n",
    "    def encode_target(y, LabEnc = LabEnc):\n",
    "        # Use label encoder, and supply with original index\n",
    "        return pd.Series(LabEnc.transform(y), index= y.index)\n",
    "\n",
    "    return create_encoded_df(X_train), create_encoded_df(X_test), encode_target(y_train), encode_target(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['income']\n",
    "predictors = data.drop(\"income\", axis = 'columns')\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_census(*train_test_split(predictors, target, test_size = .2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting models to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.87      4936\n",
      "           1       0.60      0.22      0.32      1577\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.59      0.59      6513\n",
      "weighted avg       0.75      0.78      0.73      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = simple_adaboost_fit(X_train.values.copy(), y_train.values.copy(), 50)\n",
    "preds = predict(X_test, d)\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#provided\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators = 50)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest:\\n\")\n",
    "print(classification_report(y_test, RF.predict(X_test)))\n",
    "ABC = AdaBoostClassifier(n_estimators = 50)\n",
    "ABC.fit(X_train, y_train)\n",
    "print(\"\\nAdaBoost:\\n\")\n",
    "print(classification_report(y_test, ABC.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
